/// JSON to Database Migration Utility
///
/// Migrates existing JSON transaction files to the new SQLite database system.
/// This tool provides a safe way to transition from file-based caching to database-backed storage
/// with comprehensive validation, error handling, and progress reporting.
///
/// Usage: cargo run --bin migrate_json_to_db

use std::fs;
use std::path::Path;
use serde_json;
use tokio::time::Instant;

use screenerbot::{
    transactions::Transaction,
    transactions_db::TransactionDatabase,
    global::get_transactions_cache_dir,
};

#[derive(Default)]
struct MigrationStats {
    total_files: usize,
    successful_migrations: usize,
    failed_migrations: usize,
    skipped_files: usize,
    errors: Vec<String>,
}

impl MigrationStats {
    fn report(&self, elapsed: tokio::time::Duration) {
        println!("\nğŸ”„ MIGRATION COMPLETE");
        println!("â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®");
        println!("â”‚           SUMMARY               â”‚");
        println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
        println!("â”‚ Total JSON files: {:>13} â”‚", self.total_files);
        println!("â”‚ Successfully migrated: {:>8} â”‚", self.successful_migrations);
        println!("â”‚ Failed migrations: {:>12} â”‚", self.failed_migrations);
        println!("â”‚ Skipped files: {:>16} â”‚", self.skipped_files);
        println!("â”‚ Elapsed time: {:>15.2}s â”‚", elapsed.as_secs_f64());
        println!("â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯");

        if !self.errors.is_empty() {
            println!("\nâš ï¸  ERRORS ENCOUNTERED:");
            for (i, error) in self.errors.iter().enumerate() {
                if i < 5 {
                    // Show first 5 errors
                    println!("   â€¢ {}", error);
                } else if i == 5 {
                    println!("   â€¢ ... and {} more errors", self.errors.len() - 5);
                    break;
                }
            }
        }

        let success_rate = if self.total_files > 0 {
            ((self.successful_migrations as f64) / (self.total_files as f64)) * 100.0
        } else {
            0.0
        };

        println!("\nğŸ“Š Success Rate: {:.1}%", success_rate);

        if self.failed_migrations == 0 {
            println!("âœ… All migrations completed successfully!");
        } else if success_rate >= 95.0 {
            println!("âœ… Migration mostly successful with minor issues");
        } else if success_rate >= 80.0 {
            println!("âš ï¸  Migration completed with some issues");
        } else {
            println!("âŒ Migration completed with significant issues");
        }
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ JSON to Database Migration Utility");
    println!("=====================================\n");

    // Initialize database
    println!("ğŸ“… Initializing SQLite database...");
    let database = match TransactionDatabase::new().await {
        Ok(db) => {
            println!("âœ… Database initialized successfully");
            db
        }
        Err(e) => {
            eprintln!("âŒ Failed to initialize database: {}", e);
            return Err(e.into());
        }
    };

    // Get transaction cache directory
    let cache_dir = get_transactions_cache_dir();
    println!("ğŸ“ Scanning cache directory: {}", cache_dir.display());

    if !Path::new(&cache_dir).exists() {
        println!("âš ï¸  Cache directory does not exist. Nothing to migrate.");
        return Ok(());
    }

    let start_time = Instant::now();
    let mut stats = MigrationStats::default();

    // Read all JSON files
    let entries = fs::read_dir(&cache_dir)?;
    let json_files: Vec<_> = entries
        .filter_map(|entry| entry.ok())
        .filter(|entry| {
            entry
                .file_name()
                .to_str()
                .map_or(false, |name| name.ends_with(".json"))
        })
        .collect();

    stats.total_files = json_files.len();

    if stats.total_files == 0 {
        println!("âš ï¸  No JSON transaction files found. Nothing to migrate.");
        return Ok(());
    }

    println!("ğŸ“ Found {} JSON transaction files to migrate", stats.total_files);
    println!("ğŸ”„ Starting migration...\n");

    // Process each JSON file
    for (index, entry) in json_files.iter().enumerate() {
        let file_path = entry.path();
        let file_name = entry.file_name();
        let file_name_str = file_name.to_str().unwrap_or("unknown");

        // Show progress
        if index % 100 == 0 || index == json_files.len() - 1 {
            println!(
                "ğŸ“ˆ Progress: {}/{} files processed ({:.1}%)",
                index + 1,
                stats.total_files,
                (((index + 1) as f64) / (stats.total_files as f64)) * 100.0
            );
        }

        // Extract signature from filename
        let signature = file_name_str.replace(".json", "");

        // Check if already exists in database
        if let Ok(true) = database.is_signature_known(&signature).await {
            stats.skipped_files += 1;
            continue;
        }

        // Read and parse JSON file
        let json_content = match fs::read_to_string(&file_path) {
            Ok(content) => content,
            Err(e) => {
                let error = format!("Failed to read {}: {}", file_name_str, e);
                stats.errors.push(error);
                stats.failed_migrations += 1;
                continue;
            }
        };

        let transaction: Transaction = match serde_json::from_str(&json_content) {
            Ok(tx) => tx,
            Err(e) => {
                let error = format!("Failed to parse {}: {}", file_name_str, e);
                stats.errors.push(error);
                stats.failed_migrations += 1;
                continue;
            }
        };

        // Migrate raw transaction data to database
        let status_string = match &transaction.status {
            screenerbot::transactions::TransactionStatus::Pending => "Pending",
            screenerbot::transactions::TransactionStatus::Confirmed => "Confirmed",
            screenerbot::transactions::TransactionStatus::Finalized => "Finalized",
            screenerbot::transactions::TransactionStatus::Failed(_) => "Failed",
        };

        let raw_data_string = if let Some(ref raw_data) = transaction.raw_transaction_data {
            match serde_json::to_string(raw_data) {
                Ok(s) => Some(s),
                Err(e) => {
                    let error = format!(
                        "Failed to serialize raw data for {}: {}",
                        file_name_str,
                        e
                    );
                    stats.errors.push(error);
                    None
                }
            }
        } else {
            None
        };

        // Store raw transaction
        if
            let Err(e) = database.store_raw_transaction(
                &transaction.signature,
                transaction.slot,
                transaction.block_time,
                &transaction.timestamp,
                status_string,
                transaction.success,
                transaction.error_message.as_deref(),
                raw_data_string.as_deref()
            ).await
        {
            let error = format!("Failed to store raw transaction {}: {}", file_name_str, e);
            stats.errors.push(error);
            stats.failed_migrations += 1;
            continue;
        }

        // Add to known signatures
        if let Err(e) = database.add_known_signature(&transaction.signature).await {
            let error = format!("Failed to add known signature {}: {}", file_name_str, e);
            stats.errors.push(error);
            // Don't fail the migration for this, continue
        }

        stats.successful_migrations += 1;
    }

    let elapsed = start_time.elapsed();

    // Print detailed migration report
    stats.report(elapsed);

    // Get database statistics
    println!("\nğŸ“Š DATABASE STATISTICS:");
    match database.get_database_stats().await {
        Ok(db_stats) => {
            println!("   Raw transactions: {}", db_stats.total_raw_transactions);
            println!("   Known signatures: {}", db_stats.total_known_signatures);
            println!(
                "   Database size: {:.2} MB",
                (db_stats.database_size_bytes as f64) / 1_048_576.0
            );
        }
        Err(e) => {
            println!("   Failed to get database statistics: {}", e);
        }
    }

    // Optimize database after migration
    println!("\nğŸ”§ Optimizing database...");
    if let Err(e) = database.vacuum_database().await {
        println!("âš ï¸  Failed to vacuum database: {}", e);
    }
    if let Err(e) = database.analyze_database().await {
        println!("âš ï¸  Failed to analyze database: {}", e);
    } else {
        println!("âœ… Database optimization complete");
    }

    // Provide next steps
    println!("\nğŸ¯ NEXT STEPS:");
    if stats.successful_migrations > 0 {
        println!("1. ğŸ§ª Test the database integration with your transaction processing");
        println!("2. ğŸš€ Once confident, you can remove the old JSON files");
        println!("3. ğŸ“ˆ Monitor performance improvements (expect 10x faster signature lookups)");

        if stats.failed_migrations > 0 {
            println!("4. âš ï¸  Review failed migrations and fix any issues");
            println!("5. ğŸ”„ Re-run migration to process failed files");
        }
    } else {
        println!("1. âŒ No files were migrated successfully");
        println!("2. ğŸ” Review error messages above and fix issues");
        println!("3. ğŸ”„ Re-run migration after fixing problems");
    }

    Ok(())
}
